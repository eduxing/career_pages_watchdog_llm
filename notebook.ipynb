{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f805740",
   "metadata": {},
   "source": [
    "# Development Notebook for Career Pages Watchdog    \n",
    "\n",
    "This file is meant to be able to test out functionalities before production.\n",
    "\n",
    "The system is made of the following parts:\n",
    "\n",
    "1. Career pages extractor:  Using selenium and LLMs for a given company URL we will auto-detect it's career page url where all jobs can be found.\n",
    "2. Job count extractor: Given a career page, we will try to estimate how many jobs they have published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API key is not set. Please check your .env file or environment variables.\")\n",
    "\n",
    "MODEL_QWEN = 'qwen2.5'\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "system_prompt_career_page_finder = \"\"\"Sie werden eine Reihe von Unternehmens-URLs deutschsprechender Unternehmen analysieren.\n",
    " Ihre Aufgabe besteht darin, die Karriereseite des Unternehmens zu finden und den URL zurückzugeben. Bitte antworte mit nur eine URL.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3f6d6",
   "metadata": {},
   "source": [
    "## Test Qwen running from local\n",
    "\n",
    "Be sure to run\n",
    "\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat.completions.create(\n",
    "            model=MODEL_QWEN,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt_career_page_finder},\n",
    "                {\"role\": \"user\", \"content\": \"Hallo qwen, wie geht es dir?\"},])\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46f61f",
   "metadata": {},
   "source": [
    "## Scrapper functions\n",
    "\n",
    "Now let's add the website scrapper and link extractor functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this WebsiteSelenium object from the given URL using Selenium and BeautifulSoup.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "\n",
    "        # Set up Selenium WebDriver with headless Chrome\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Prevent detection\n",
    "        chrome_options.add_argument(\"--disable-infobars\")  # Disable \"Chrome is being controlled\" infobar\n",
    "       \n",
    "        # Remove the default \"user-agent\" string\n",
    "        # chrome_options.add_argument(\"user-agent=YOUR_CUSTOM_USER_AGENT\")  # Use a user-agent string from a real browser\n",
    "\n",
    "\n",
    "        service = Service()  # Use default ChromeDriver path\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Fetch the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Get the page source\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            links = [link.get('href') for link in soup.find_all('a')]\n",
    "            self.links = [link for link in links if link]\n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "        user_prompt = f\"Hier ist die Liste der Links auf der Website von {website.url} - \"\n",
    "        user_prompt += \"Sie sollten den einen Link finden, der am wahrscheinlichsten die Karriereseite enthält, auf der die offenen Stellenlisten stehen. Bitte nur mit einen einzigen link antworten.\\n\"\n",
    "        user_prompt += \"Links (einige könnten relative Links sein):\"\n",
    "        user_prompt += \"\\n\".join(website.links)\n",
    "        return user_prompt\n",
    "\n",
    "def get_career_page(url,model=MODEL_LLAMA):\n",
    "        website = Website(url)\n",
    "        if model==MODEL_GPT:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt_career_page_finder},\n",
    "                    {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "                ]\n",
    "            )\n",
    "            result = response.choices[0].message.content\n",
    "            return result\n",
    "        else:\n",
    "            response = ollama.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt_career_page_finder},\n",
    "                    {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "                ]\n",
    "            )\n",
    "            result = response.choices[0].message.content\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d2ed1",
   "metadata": {},
   "source": [
    "## Test with one URL\n",
    "\n",
    "A simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_career_page(\"https://www.sparkasse.de\",'llama3.2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e41729",
   "metadata": {},
   "source": [
    "## Now let's look at the companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Company:\n",
    "    def __init__(self, company_name, company_url):\n",
    "        \"\"\"\n",
    "        Initialize a Company object with the given name and URL.\n",
    "\n",
    "        Args:\n",
    "            company_name (str): The name of the company.\n",
    "            company_url (str): The URL of the company's website.\n",
    "        \"\"\"\n",
    "        self.company_name = company_name\n",
    "        self.company_url = company_url\n",
    "        self.career_url = None  # This will be populated later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c03230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_companies_from_csv(file_path, model=MODEL_LLAMA):\n",
    "    \"\"\"\n",
    "    Process companies from a CSV file, extract their career page URLs, and return a list of Company objects.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing company data.\n",
    "        model (str): The model to use for extracting career page URLs.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Company objects with career URLs populated.\n",
    "    \"\"\"\n",
    "    companies = []\n",
    "\n",
    "    # Open the CSV file and iterate over its rows\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)  # Use DictReader to access columns by name\n",
    "        for row in reader:\n",
    "            # Create a Company object for each row\n",
    "            company = Company(company_name=row['company_name'], company_url=row['company_url'])\n",
    "            company.career_url = get_career_page(company.company_url, model)  # Get the career page URL\n",
    "            print(f\"Company Name: {company.company_name}, Career URL: {company.career_url}\")\n",
    "            companies.append(company)  # Add the Company object to the companies list\n",
    "\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ae36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_companies_from_csv('data/sampledomains.csv', model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158898c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_companies_from_csv('data/sampledomains.csv', model=MODEL_LLAMA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careerpageswatchdog-Xx4QWZVo-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
